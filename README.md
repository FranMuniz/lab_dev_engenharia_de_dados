## LaboratÃ³rio de Desenvolvimento - Engenharia de Dados

Um laboratÃ³rio completo para estudos em **Engenharia de Dados**, rodando via **Docker**.  
Aqui vocÃª encontra um ambiente integrado com **Spark, PySpark, Jupyter, PostgreSQL e Airflow**, pronto para treinar desde consultas SQL atÃ© orquestraÃ§Ã£o de pipelines de dados.

---

### ğŸš€ Tecnologias

- **Apache Spark** â†’ processamento distribuÃ­do de dados.
- **PySpark** â†’ API Python para manipulaÃ§Ã£o de dados no Spark.
- **Jupyter Notebook** â†’ ambiente interativo para experimentos.
- **PostgreSQL** â†’ banco de dados relacional para integraÃ§Ã£o com Spark e Airflow.
- **Apache Airflow** â†’ orquestrador de workflows e pipelines de dados.

<p align="center">
  <img src="https://img.shields.io/badge/Spark-FF6F00?style=for-the-badge&logo=apachespark&logoColor=white"/>
  <img src="https://img.shields.io/badge/PySpark-EE4C2C?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Spark_SQL-FF6F00?style=for-the-badge&logo=apachespark&logoColor=white"/>
  <img src="https://img.shields.io/badge/Postgres-316192?style=for-the-badge&logo=postgresql&logoColor=white"/>
  <img src="https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white"/>
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white"/>
</p>

---

### ğŸ“Œ Roadmap de Estudos

- [ ] Fundamentos de Spark (RDD, DataFrames, Lazy Evaluation)  
- [ ] OperaÃ§Ãµes bÃ¡sicas (`select`, `filter`, `groupBy`, `join`)  
- [ ] Leitura e escrita de dados (CSV, Parquet, PostgreSQL)  
- [ ] Spark SQL  
- [ ] IntegraÃ§Ã£o Spark + Airflow  
- [ ] Pipelines completos de Engenharia de Dados  

---

## ğŸ“‚ Estrutura de Pastas

```bash
lab_dev_engenharia_de_dados/
â”‚â”€â”€ .env                 # variÃ¡veis de ambiente
â”‚â”€â”€ .gitignore           # arquivos/diretÃ³rios ignorados pelo Git
â”‚â”€â”€ docker-compose.yml   # definiÃ§Ã£o dos serviÃ§os
â”‚â”€â”€ Dockerfile           # imagem customizada para o container
â”‚â”€â”€ README.md            # documentaÃ§Ã£o do projeto
â”‚â”€â”€ notebooks/           # Jupyter Notebooks
â”‚â”€â”€ dags/                # DAGs do Airflow
â”‚â”€â”€ logs/                # logs do Airflow
â”‚â”€â”€ plugins/             # plugins do Airflow
```
---

## âš™ï¸ Como rodar o ambiente

### 1ï¸âƒ£ Clone este repositÃ³rio
Clone o repositÃ³rio e entre na pasta do projeto:  
**Comandos:**  
```bash
git clone https://github.com/seu-usuario/meu-lab-dados.git  
cd lab_dev_engenharia_de_dados/
```

---

### 2ï¸âƒ£ Configure o arquivo .env
### PostgreSQL
```
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin
POSTGRES_DB=mydb
```

### Jupyter (opcional, jÃ¡ estÃ¡ sem token)
```
JUPYTER_PASSWORD_HASH=CHAVE_HASH_AQUI
```

### Airflow
```
AIRFLOW_DB_USER=admin
AIRFLOW_DB_PASSWORD=admin
AIRFLOW_DB_NAME=airflow
AIRFLOW_FERNET_KEY=CHAVE_FERNET_AQUI
```
Gere a chave Fernet com:
```bash
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
```

---

### 3ï¸âƒ£ Suba os serviÃ§os com Docker Compose
**Comando:**  
```bash
docker-compose up -d
```
---

### 4ï¸âƒ£ Acesse os serviÃ§os

**ğŸ”¥ Spark Master**  
[http://localhost:8080](http://localhost:8080)  
Interface web do Spark para acompanhar workers e jobs.

**âš¡ Spark Worker**  
[http://localhost:8081](http://localhost:8081)  
Interface web do worker conectado ao cluster Spark.

**ğŸ“’ Jupyter Notebook**  
[http://localhost:8888](http://localhost:8888)  
Ambiente interativo com PySpark jÃ¡ configurado.  
NÃ£o Ã© necessÃ¡rio informar token ou senha para acessar.

**ğŸ˜ PostgreSQL**  
Host: `localhost:5432`  
Banco de dados relacional para integraÃ§Ã£o com Spark e Airflow.  
- **UsuÃ¡rio:** `${POSTGRES_USER}`  
- **Senha:** `${POSTGRES_PASSWORD}`  
- **Banco:** `${POSTGRES_DB}`  

**ğŸŒ¬ï¸ Airflow Webserver**  
[http://localhost:8082](http://localhost:8082)  
Interface web do Airflow para monitorar DAGs.  
- UsuÃ¡rio padrÃ£o: `admin`  
- Senha padrÃ£o: `admin`  

**ğŸ“… Airflow Scheduler**  
ResponsÃ¡vel por agendar e executar as DAGs.  

**ğŸ¯ Airflow Triggerer**  
ResponsÃ¡vel por lidar com sensores e disparos assÃ­ncronos.  

