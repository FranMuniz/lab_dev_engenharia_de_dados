## LaboratÃ³rio de Desenvolvimento - Engenharia de Dados

Um laboratÃ³rio completo para estudos em **Engenharia de Dados**, rodando via **Docker**.  
Aqui vocÃª encontra um ambiente integrado com **Spark, PySpark, Jupyter, PostgreSQL e Airflow**, pronto para treinar desde consultas SQL atÃ© orquestraÃ§Ã£o de pipelines de dados.

---

### ğŸš€ Tecnologias

- **Apache Spark** â†’ processamento distribuÃ­do de dados.
- **PySpark** â†’ API Python para manipulaÃ§Ã£o de dados no Spark.
- **Jupyter Notebook** â†’ ambiente interativo para experimentos.
- **PostgreSQL** â†’ banco de dados relacional para integraÃ§Ã£o com Spark e Airflow.
- **Apache Airflow** â†’ orquestrador de workflows e pipelines de dados.

<p align="center">
  <img src="https://img.shields.io/badge/Spark-FF6F00?style=for-the-badge&logo=apachespark&logoColor=white"/>
  <img src="https://img.shields.io/badge/Spark_SQL-FF6F00?style=for-the-badge&logo=apachespark&logoColor=white"/>
  <img src="https://img.shields.io/badge/Postgres-316192?style=for-the-badge&logo=postgresql&logoColor=white"/>
  <img src="https://img.shields.io/badge/Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white"/>
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white"/>
  <img src="https://img.shields.io/badge/PySpark-EE4C2C?style=for-the-badge&logo=python&logoColor=white"/>
</p>

---

### ğŸ“Œ Roadmap de Estudos

- [ ] Fundamentos de Spark (RDD, DataFrames, Lazy Evaluation)  
- [ ] OperaÃ§Ãµes bÃ¡sicas (`select`, `filter`, `groupBy`, `join`)  
- [ ] Leitura e escrita de dados (CSV, Parquet, PostgreSQL)  
- [ ] Spark SQL  
- [ ] IntegraÃ§Ã£o Spark + Airflow  
- [ ] Pipelines completos de Engenharia de Dados  

---

## ğŸ“‚ Estrutura de Pastas

```bash
lab_dev_engenharia_de_dados/
â”‚â”€â”€ docker-compose.yml   # definiÃ§Ã£o dos serviÃ§os
â”‚â”€â”€ notebooks/           # Jupyter Notebooks com seus estudos em PySpark
â”‚â”€â”€ dags/                # DAGs do Airflow
â”‚â”€â”€ logs/                # logs do Airflow
â”‚â”€â”€ plugins/             # plugins do Airflow

---

## âš™ï¸ Como rodar o ambiente

### 1ï¸âƒ£ Clone este repositÃ³rio
Clone o repositÃ³rio e entre na pasta do projeto:  
**Comandos:**  
git clone https://github.com/seu-usuario/meu-lab-dados.git  
cd lab_dev_engenharia_de_dados/

---

### 2ï¸âƒ£ Suba os serviÃ§os com Docker Compose
**Comando:**  
docker-compose up -d

---

### 3ï¸âƒ£ Acesse os serviÃ§os

**ğŸ”¥ Spark Master**  
[http://localhost:8080](http://localhost:8080)  
Interface web do Spark para acompanhar workers e jobs.

**ğŸ“’ Jupyter Notebook**  
[http://localhost:8888](http://localhost:8888)  
Ambiente interativo com PySpark jÃ¡ configurado.  
Para ver o token de acesso:  
docker logs jupyter

**ğŸ˜ PostgreSQL**  
Host: `localhost:5432`  
Banco de dados relacional para integraÃ§Ã£o com Spark e Airflow.  
- **UsuÃ¡rio:** admin  
- **Senha:** admin  
- **Banco:** mydb
